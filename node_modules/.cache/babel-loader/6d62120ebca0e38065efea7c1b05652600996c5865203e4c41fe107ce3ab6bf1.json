{"ast":null,"code":"var _jsxFileName = \"E:\\\\Sigma Web Development Course\\\\Emotion-Aware Virtual Listener\\\\src\\\\App.jsx\",\n  _s = $RefreshSig$();\nimport React, { useState } from 'react';\nimport MicButton from './components/MicButton';\nimport TranscriptDisplay from './components/TranscriptDisplay';\nimport ResponseArea from './components/ResponseArea';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction App() {\n  _s();\n  const [transcript, setTranscript] = useState('');\n  const [response, setResponse] = useState('');\n  const [isRecording, setIsRecording] = useState(false);\n  const handleTranscriptUpdate = newTranscript => {\n    setTranscript(newTranscript);\n    // Simulate emotion detection and response (replace with actual API calls)\n    setResponse(\"It sounds like you're feeling overwhelmed. I'm here to listen if you want to share more.\");\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"min-h-screen bg-gradient-to-br from-blue-50 to-purple-50 flex items-center justify-center p-4\",\n    children: /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"bg-white rounded-lg shadow-xl p-6 max-w-2xl w-full\",\n      children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n        className: \"text-2xl font-bold text-center text-gray-800 mb-6\",\n        children: \"Emotion-Aware Virtual Listener\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 20,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(MicButton, {\n        isRecording: isRecording,\n        setIsRecording: setIsRecording,\n        onTranscriptUpdate: handleTranscriptUpdate\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 23,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(TranscriptDisplay, {\n        transcript: transcript\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 28,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(ResponseArea, {\n        response: response\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 29,\n        columnNumber: 17\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 19,\n      columnNumber: 13\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 18,\n    columnNumber: 9\n  }, this);\n}\n_s(App, \"JLhO6NUbMJxEsC/OykN9hLYwFIs=\");\n_c = App;\nexport default App;\nvar _c;\n$RefreshReg$(_c, \"App\");","map":{"version":3,"names":["React","useState","MicButton","TranscriptDisplay","ResponseArea","jsxDEV","_jsxDEV","App","_s","transcript","setTranscript","response","setResponse","isRecording","setIsRecording","handleTranscriptUpdate","newTranscript","className","children","fileName","_jsxFileName","lineNumber","columnNumber","onTranscriptUpdate","_c","$RefreshReg$"],"sources":["E:/Sigma Web Development Course/Emotion-Aware Virtual Listener/src/App.jsx"],"sourcesContent":["import React, { useState } from 'react';\r\nimport MicButton from './components/MicButton';\r\nimport TranscriptDisplay from './components/TranscriptDisplay';\r\nimport ResponseArea from './components/ResponseArea';\r\n\r\nfunction App() {\r\n    const [transcript, setTranscript] = useState('');\r\n    const [response, setResponse] = useState('');\r\n    const [isRecording, setIsRecording] = useState(false);\r\n\r\n    const handleTranscriptUpdate = (newTranscript) => {\r\n        setTranscript(newTranscript);\r\n        // Simulate emotion detection and response (replace with actual API calls)\r\n        setResponse(\"It sounds like you're feeling overwhelmed. I'm here to listen if you want to share more.\");\r\n    };\r\n\r\n    return (\r\n        <div className=\"min-h-screen bg-gradient-to-br from-blue-50 to-purple-50 flex items-center justify-center p-4\">\r\n            <div className=\"bg-white rounded-lg shadow-xl p-6 max-w-2xl w-full\">\r\n                <h1 className=\"text-2xl font-bold text-center text-gray-800 mb-6\">\r\n                    Emotion-Aware Virtual Listener\r\n                </h1>\r\n                <MicButton \r\n                    isRecording={isRecording} \r\n                    setIsRecording={setIsRecording}\r\n                    onTranscriptUpdate={handleTranscriptUpdate}\r\n                />\r\n                <TranscriptDisplay transcript={transcript} />\r\n                <ResponseArea response={response} />\r\n            </div>\r\n        </div>\r\n    );\r\n}\r\n\r\nexport default App;"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,QAAQ,OAAO;AACvC,OAAOC,SAAS,MAAM,wBAAwB;AAC9C,OAAOC,iBAAiB,MAAM,gCAAgC;AAC9D,OAAOC,YAAY,MAAM,2BAA2B;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAErD,SAASC,GAAGA,CAAA,EAAG;EAAAC,EAAA;EACX,MAAM,CAACC,UAAU,EAAEC,aAAa,CAAC,GAAGT,QAAQ,CAAC,EAAE,CAAC;EAChD,MAAM,CAACU,QAAQ,EAAEC,WAAW,CAAC,GAAGX,QAAQ,CAAC,EAAE,CAAC;EAC5C,MAAM,CAACY,WAAW,EAAEC,cAAc,CAAC,GAAGb,QAAQ,CAAC,KAAK,CAAC;EAErD,MAAMc,sBAAsB,GAAIC,aAAa,IAAK;IAC9CN,aAAa,CAACM,aAAa,CAAC;IAC5B;IACAJ,WAAW,CAAC,0FAA0F,CAAC;EAC3G,CAAC;EAED,oBACIN,OAAA;IAAKW,SAAS,EAAC,+FAA+F;IAAAC,QAAA,eAC1GZ,OAAA;MAAKW,SAAS,EAAC,oDAAoD;MAAAC,QAAA,gBAC/DZ,OAAA;QAAIW,SAAS,EAAC,mDAAmD;QAAAC,QAAA,EAAC;MAElE;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eACLhB,OAAA,CAACJ,SAAS;QACNW,WAAW,EAAEA,WAAY;QACzBC,cAAc,EAAEA,cAAe;QAC/BS,kBAAkB,EAAER;MAAuB;QAAAI,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAC9C,CAAC,eACFhB,OAAA,CAACH,iBAAiB;QAACM,UAAU,EAAEA;MAAW;QAAAU,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAE,CAAC,eAC7ChB,OAAA,CAACF,YAAY;QAACO,QAAQ,EAAEA;MAAS;QAAAQ,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAE,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACnC;EAAC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACL,CAAC;AAEd;AAACd,EAAA,CA3BQD,GAAG;AAAAiB,EAAA,GAAHjB,GAAG;AA6BZ,eAAeA,GAAG;AAAC,IAAAiB,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}